Skip to content News Menu Search form Search term Home Find Stories For Journalists Contact Image credit: Getty Images April 13, 2022 What Stanford research reveals about disinformation and how to address it Stanford scholars from across the social sciences are studying the threats disinformation poses to democracy. Here is some of their research. Facebook Twitter LinkedIn Email By Melissa De Witte Over the past decade, the spread of disinformation online has become a problem facing the U.S. and the world. Increasingly, domestic and foreign adversaries have used it as a way to unleash chaos on democratic processes, upend democratic norms and weaken confidence in public institutions, according to Stanford scholars. While propaganda and disinformation have long been used by malign actors to intentionally mislead and manipulate the public, disinformation online can spread fast and far across networks anonymously, cheaply and efficiently, making it a challenging problem to address. The internet and social media platforms have become “weaponized” to purposefully confuse, agitate and divide civil society, said Eileen Donahoe, executive director of Stanford’s Global Digital Policy Incubator and former U.S. Ambassador to the UN Human Rights Council. “Democratic governments are now seized with the fact that digital information platforms have been exploited by malign actors to spread propaganda and disinformation, wreaking havoc on democratic elections and eroding trust in the digital information realm,” said Donahoe in an online commentary published by the Stanford’s Cyber Policy Center. Donahoe and Stanford scholars from across the social sciences are studying the threats disinformation poses to democracy and also other areas of public and private life, such as health and education. In many instances, researchers are providing specific recommendations for what governments, digital platforms and the public can do to counter its deleterious effects. Here are some of those findings and recommendations, as well as insight into the role disinformation played during the global pandemic and more recently, the Russian invasion of Ukraine. Image credit: Getty Images How disinformation can hinder democracy Understanding how disinformation online has endangered democracy and democratic norms is incredibly nuanced. When considering the dynamics at play, it is important to not conflate disinformation and the internet communication environment with existing issues it is entangled in (and at times, exploits), such as rising populism and polarization, said Stanford legal scholar and co-director of the Cyber Policy Center Nathaniel Persily in a 2019 report for the Kofi Annan Commission on Elections and Democracy in the Digital Age. Rather, it is important to understand what conditions lead to disinformation fomenting in these online spaces. “The challenge for anybody analyzing the particular stresses that the new technologies and platforms pose for democracies is to isolate the unique features of this new form of communication that threaten the core components of elections, campaigns and democratic decisionmaking,” Persily said. Persily, and other Stanford scholars, have been examining what makes disinformation unique in the digital age and the tactics foreign and domestic actors use to discredit and cause harm through information environments, as well as what can be done about it. Image credit: Getty Images Share this card Facebook Twitter LinkedIn Email University Affairs Disinformation is weakening democracy, Barack Obama said Former U.S. President Barack Obama delivered a keynote address about how information is created and consumed, and the threat that disinformation poses to democracy. Top technology policy priorities for the new administration Now is the time to rally the world around a democratic vision of digital society, says Stanford's Eileen Donahoe. Social Sciences Journalism and democracy In a complex news environment, Stanford professors urge voters to be careful consumers of political information and to think hard about where information comes from and how it reaches them. Research Sleuthing for misinformation about voting Ahead of the 2020 election, Stanford students investigate the spread of mis- and disinformation online as part of their work with the Election Integrity Partnership. Social Sciences Strategies to secure American elections Stanford scholars outline a detailed strategy for how to protect the integrity of American elections – including recommendations such as requiring a paper trail of every vote cast and publishing information about a campaign’s connections with foreign nationals. Social Sciences Election Integrity Partnership releases final report on mis- and disinformation in 2020 U.S. election Researchers from Stanford University, the University of Washington, Graphika and Atlantic Council’s DFRLab released their findings in The Long Fuse: Misinformation and the 2020 Election. Social Sciences Study suggests Facebook’s war on fake news is gaining ground In one of the first studies of its kind, Stanford economist Matthew Gentzkow is shedding light on a key question: Are Facebook's countermeasures making a difference? Law & Policy Stanford study examines fake news and the 2016 presidential election Fabricated stories favoring Donald Trump were shared 30 million times, but the most widely circulated hoaxes were seen by only a small fraction of Americans. How to restore faith in America’s elections Our recent election focused attention on the mechanics of democracy as never before. Nate Persily, an expert in election law, sizes things up and suggests ways to regain trust in the institution. Image credit: Getty Images How to spot and stop the spread of disinformation Stanford researchers at the Graduate School of Education have found that many high school students are unable to evaluate the credibility of information they read on the internet – a finding they describe as “troubling.” “Reliable information is to civic health what proper sanitation and potable water are to public health. A polluted information supply imperils our nation’s civic health,” said Sam Wineburg, the Margaret Jacks Professor of Education, Emeritus, and founder of the Stanford History Education Group (SHEG), in a report he co-authored with SHEG director Joel Breakstone, PhD ’13, and director of assessment Mark Smith, PhD ’14. Their research reveals just how unprepared high school students are to discern fact from fiction. In a survey with a national sample of high school students, they found that two-thirds of students were unable to distinguish between news stories and ads (despite being labeled “Sponsored Content”) and 52% of students believed a grainy video that claimed to show ballot stuffing in the 2016 Democratic primaries constituted “strong evidence” of voter fraud in the U.S when in actuality the video was filmed in Russia. “Education moves slowly. Technology doesn’t. If we don’t act with urgency, our students’ ability to engage in civic life will be the casualty,” Wineburg and his colleagues wrote. Wineburg and his colleagues have created a free curriculum called Civic Online Reasoning for educators to teach students the skills they need to evaluate information online. The scholars found that a small intervention can lead to an outsized impact on students’ ability to judge the credibility of digital content. Here is some of that research and other Stanford scholarship that identifies ways to counter the spread of fake news and tips on how to spot and stop it. Image credit: Getty Images Share this card Facebook Twitter LinkedIn Email Social Sciences High school students are unequipped to spot ‘fake news’ With the 2020 presidential election approaching, new research by Stanford education scholars finds that prospective young voters are poorly equipped to evaluate the sources of online content. Social Sciences To foil fake news, focus on infectiousness New research on the ways fake news spreads via social media refines conventional wisdom and offers potential solutions to a vexing problem. Social Sciences Seven tips for spotting disinformation on the Russia-Ukraine war A disinformation researcher shares what she and her team watch for when analyzing social media posts and other online reports related to the Russian invasion of Ukraine. Social Sciences Motivation, provenance of disinformation is pivotal in news reporting Stanford scholars Janine Zacharia and Andrew Grotto discuss strategies for reporters and editors to write about disinformation, leaked material and propaganda in a responsible and timely way. Social Sciences Fact checkers outperform historians when evaluating online information A new report from the Stanford History Education Group finds that fact checkers read less but learn more – far outpacing historians and top college students. Social Sciences Judging fact from fiction online Research from the Stanford History Education Group shows how easily young people are deceived by information on the internet – and what schools can do about it. Preparing for the age of deepfakes and disinformation Advances in artificial intelligence promise to make creating convincing fake multimedia content like video, images or audio relatively easy for many. Science & Technology Using AI to detect seemingly perfect deep-fake videos Researchers at Stanford and UC Berkeley have unveiled an AI-based approach to detect lip-sync technology. Society needs to adapt to a world of widespread disinformation Renée DiResta is leading the fight against online disinformation. On the World Class Podcast, she describes what it’s like to expose malign actors in the emerging world of ceaseless propaganda and conspiracy theories. Image credit: Getty Images How disinformation hurts health & well being Throughout the global pandemic, public health organizations and social media platforms have been trying to tackle problems of disinformation as it relates to COVID-19, from causes to treatment. Most recently, Stanford researchers have been examining disinformation about the COVID-19 vaccine. As disinformation scholar Renee DiResta points out, disinformation about vaccines is practically as old as the vaccine itself: Shortly after Edward Jenner created the vaccine in 1796 to protect people against smallpox, opposition to this new life-saving technology proliferated. Today, online communities foment fears by offering digital spaces for disinformation to flourish in largely echo chambers where anti-vaccination activists, unrestrained by editorial gatekeepers, have been able to broadcast their claims, unchecked. Despite social media platforms developing policies against vaccine-related disinformation, anti-vaccination activists have become savvy at avoiding accountability for the misleading and pseudoscientific claims they spout. “There are very real-world impacts to vaccine hesitancy at this moment in time,” said DiResta, the technical research manager at Stanford Internet Observatory. “Myths, rumors and disinformation contribute to vaccine hesitancy, and thinking about our information environment is part of understanding the public health quandary that we find ourselves in.” DiResta and her team have put together specific recommendations on how to stop disinformation about the vaccine from spreading. Here is some of that work, as well as other research scholars have done, to tackle disinformation as it relates to public health and well-being. Image credit: Getty Images Share this card Facebook Twitter LinkedIn Email Science & Technology Curbing the spread of COVID-19 vaccine-related mis- and disinformation In a new report, Stanford researchers outline steps that public health officials and the research community can take to curb the spread of vaccine-related mis- and disinformation online. Social Sciences Why fake news about coronavirus is appealing (and how to avoid it) Check health-related information about the coronavirus from established news sources rather than from shared stories in social media, advises Professor of Communication Jeff Hancock. 5 Questions: Kevin Schulman on encouraging COVID-19 vaccination in a politically polarized country COVID-19 vaccination rates must reach 80% to achieve herd immunity, but only about 60% of Americans are willing to be vaccinated, according to the Pew Research Center. Stanford physician and economist Kevin Schulman suggests marketing tactics to boost compliance. How misinformation, medical mistrust fuel vaccine hesitancy More than two dozen experts discussed how to combat misinformation about COVID-19 and vaccines at a virtual conference. Science & Technology Social Sciences Facebook Twitter LinkedIn Email What to read next: Science & Technology Small modular reactors produce high levels of nuclear waste Small modular reactors, long touted as the future of nuclear energy, will actually generate more radioactive waste than conventional nuclear power plants, according to research from Stanford and the University of British Columbia. Science & Technology Q&A: How the aging immune system impacts brain health Katrin Andreasson, professor of neurology and neurological sciences, talks about the role the aging immune system plays in the development of age-related brain diseases. Science & Technology What the humble planarian teaches us about the building blocks of life A bioengineer studies the flatworms' ability to regenerate nerves, muscle, and other tissue. “One of the big questions we want to answer is how it does this on a genetic level?” Stanford Report To receive Stanford news daily, subscribe to Stanford Report. For Journalists Press Releases Media Contacts Stanford Experts See Also Contact Stanford News Faculty / Staff Resources Events Events calendar Stanford News is a publication of Stanford University Communications Stanford Home Maps & Directions Search Stanford Emergency Info Terms of Use Privacy Copyright Trademarks Non-Discrimination Accessibility © Stanford University. Stanford, California 94305.